{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv file & define image directory\n",
    "data = pd.read_csv('balanced_dataset.csv')\n",
    "image_dir = r'D:\\Self Study\\3 Cancer Image Classification\\train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerImageDataset(Dataset):\n",
    "    def __init__(self, csv_data, image_dir, transform=None):\n",
    "        self.csv_data = csv_data\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the image name and label\n",
    "        image_id = self.csv_data.iloc[idx]['isic_id']\n",
    "        label = self.csv_data.iloc[idx]['target']\n",
    "        \n",
    "        # load the image\n",
    "        image_path = os.path.join(self.image_dir, f\"{image_id}.jpg\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (resize, normalize, and augment if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),         # Convert to tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = CancerImageDataset(data, image_dir, transform=transform)\n",
    "\n",
    "# Split into training and validation datasets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MelanomaModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MelanomaModel, self).__init__()\n",
    "        self.base_model = models.efficientnet_b3(pretrained=True)\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(self.base_model.classifier[1].in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "model = MelanomaModel().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nStarting epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE).float()\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "\n",
    "            # Loss computation\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation loop\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE).float()\n",
    "                outputs = model(images).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 1/4\n",
      "Epoch 1/4, Train Loss: 0.6783, Val Loss: 0.6889\n",
      "\n",
      "Starting epoch 2/4\n",
      "Epoch 2/4, Train Loss: 0.6234, Val Loss: 0.6198\n",
      "\n",
      "Starting epoch 3/4\n",
      "Epoch 3/4, Train Loss: 0.5644, Val Loss: 0.5409\n",
      "\n",
      "Starting epoch 4/4\n",
      "Epoch 4/4, Train Loss: 0.4603, Val Loss: 0.4745\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 4\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Evaluation on 20 Images:\n",
      "Accuracy: 0.9500\n",
      "Precision: 0.9167\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9565\n",
      "True Labels: [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]\n",
      "Predictions: [True, True, False, True, False, True, True, False, False, False, False, True, True, True, False, False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to evaluate the model on 10 random images\n",
    "def evaluate_random_images(model, dataset, num_images=10):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Randomly select 10 indices from the dataset\n",
    "    random_indices = random.sample(range(len(dataset)), num_images)\n",
    "    \n",
    "    # Initialize lists to store predictions and true labels\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in random_indices:\n",
    "            # Get the image and label\n",
    "            image, label = dataset[idx]\n",
    "            \n",
    "            # Add batch dimension and move to DEVICE\n",
    "            image = image.unsqueeze(0).to(DEVICE)\n",
    "            label = label.to(DEVICE).float()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(image).squeeze()\n",
    "            predicted_label = (output > 0.5).item()  # Convert sigmoid output to binary prediction\n",
    "            \n",
    "            # Store the true label and prediction\n",
    "            true_labels.append(label.item())\n",
    "            predictions.append(predicted_label)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, zero_division=1)\n",
    "    recall = recall_score(true_labels, predictions, zero_division=1)\n",
    "    f1 = f1_score(true_labels, predictions, zero_division=1)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Random Evaluation on {num_images} Images:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"True Labels: {true_labels}\")\n",
    "    print(f\"Predictions: {predictions}\")\n",
    "\n",
    "# Evaluate the model on 10 random images\n",
    "evaluate_random_images(model, dataset, num_images=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"models/melanoma_model.pt\"\n",
    "torch.save(model.state_dict(), model_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
